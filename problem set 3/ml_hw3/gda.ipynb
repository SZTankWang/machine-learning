{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "oriental-visit",
   "metadata": {},
   "source": [
    "# Problem 2: Linear Discriminative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-pendant",
   "metadata": {},
   "source": [
    "## 2.2 implement GaussianDiscAnalysis class, fit the model with breast cancer data (using the first two features), plot the testing data and the decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "graphic-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class GaussianDiscAnalysis:\n",
    "    \"\"\"\n",
    "    Fits a Linear Discriminant Analysis Model for binary class\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_phi(self, y):\n",
    "        \"\"\"\n",
    "        calculate prior probability of positive class: P(Y=1)\n",
    "        :param y: matrix of nx1\n",
    "        :return: the prior probability\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def compute_mu(self, X, y):\n",
    "        \"\"\"\n",
    "        compute Mu for the positive class and negative class\n",
    "        :param X: matrix of nxd  (n is sample size and d is number of features)\n",
    "        :param y: matrix of nx1\n",
    "        :param cls: integer 0/1\n",
    "        :return: matrix of 2xd with the first row being the mean of 0 class and the second row being the mean of class 1\n",
    "        \"\"\"\n",
    "        # initialize the matrix Mu\n",
    "        mu = np.zeros((2, X.shape[-1]), dtype=np.float32)\n",
    "        \n",
    "        # compute Mu using the formula\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def compute_sigma(self, X, y):\n",
    "        \"\"\"\n",
    "        compute the common covariance matrix which is shared by the two classes\n",
    "        :param X: matrix of nxd  (n is sample size and d is number of features)\n",
    "        :param y: matrix of nx1\n",
    "        :return:  dxd covariance matrix\n",
    "        \"\"\"\n",
    "        # compute Mu first\n",
    "        mu = self.compute_mu(X, y)\n",
    "        \n",
    "        # compute the covariance matrix using the formula\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def gaussian_p(self, x, cls):\n",
    "        \"\"\"\n",
    "        Probability of X=x given y (Assume the conditional distribution is gaussian distribution)\n",
    "        To get the inverse and determinant of an matrix you can use the module np.linalg\n",
    "        :param x: 1D vector which is the feature vector for one observation\n",
    "        :param cls: interger 0/1\n",
    "        :return: probability density value of X=x|Y=cls\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        \n",
    "        # compute d\n",
    "        \n",
    "        # compute the inverse of sigma\n",
    "        \n",
    "        # compute determinant of sigma\n",
    "        \n",
    "        # compute the probability density value of X=x|Y=cls\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Computes mean, covariance and proabilities of y (phi)\"\"\"\n",
    "        self.d = X.shape[1]\n",
    "        # the prior probability of Y=1\n",
    "        self.phi = self.compute_phi(y)\n",
    "        # mean of X for each class\n",
    "        self.mu = self.compute_mu(X, y)\n",
    "        # the common covariance matrix\n",
    "        self.sigma = self.compute_sigma(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        make prediction based on P(Y|X).\n",
    "        You can effectively compare P(Y=1)*P(X|Y=1) v.s. P(Y=0)*P(X|Y=0)\n",
    "        :param X: 2D vector which each row representing a data point\n",
    "        :return: 1D vector which each element being 0/1\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        \n",
    "        # for each data point, calculate P(Y=1)*P(X|Y=1) and P(Y=0)*P(X|Y=0)\n",
    "        # if P(Y=1)*P(X|Y=1) > P(Y=0)*P(X|Y=0), then y is predicted to be 1\n",
    "        # else, y is predicted to be 0\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "generic-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = load_breast_cancer()\n",
    "data = np.array(breast_cancer.data)\n",
    "label = np.array(breast_cancer.target)\n",
    "data = MinMaxScaler().fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "owned-whale",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training set and test set (only keep the first two features )\n",
    "train_data, test_data, train_label, test_label = train_test_split(data[:, :2], label, test_size=1 / 4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "tired-issue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model using the training data\n",
    "gda = GaussianDiscAnalysis()\n",
    "gda.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "capable-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for the test data, print out the accuracy score\n",
    "test_pred = gda.predict(test_data)\n",
    "\n",
    "# print('the accuracy score is {}'.format(accuracy_score(test_label, test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "moral-juice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"P2.2 plot the data and the decision boundary'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"P2.2 plot the data and the decision boundary\"\"\"\n",
    "# data visualization\n",
    "\n",
    "# plot the testing data (x axis: first feature, y axis: second feature), use different colors for the two classes\n",
    "\n",
    "# on the same figure, plot the decision boundary\n",
    "\n",
    "# print out the intercept and the slope of the linear decision boundary\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-thickness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
