{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "executed-disorder",
   "metadata": {},
   "source": [
    "# Problem 1 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-grade",
   "metadata": {},
   "source": [
    "## 1.1 Fit a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "complicated-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class LogisticRegressionGD:\n",
    "    def __init__(self, lr=0.01, fit_intercept=True, max_epoch=1e5, tolerance=1e-7, verbose=True):\n",
    "        self.lr = lr\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.max_epoch = max_epoch\n",
    "        self.tolerance = tolerance\n",
    "        self.verbose = True\n",
    "\n",
    "    def add_intercept(self, X):\n",
    "        # add an extra column for the intercept\n",
    "        intercept = np.ones([X.shape[0], 1])\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def cost_function(self, h, y):\n",
    "        # calculate the loss\n",
    "        # return the loss\n",
    "        \n",
    "        # TODO\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : shape (n_samples, n_features)\n",
    "            Training data\n",
    "        y : shape (n_samples,)\n",
    "            Target values, 1 or 0\n",
    "        epochs : The number of epochs\n",
    "        '''\n",
    "\n",
    "        # initialize the parameters\n",
    "        if self.fit_intercept:\n",
    "            X = self.add_intercept(X)\n",
    "        \n",
    "        # initialize the coefficients\n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "\n",
    "        tol = 1e10\n",
    "        n_epoch = 1\n",
    "        while tol > self.tolerance and n_epoch <= self.max_epoch:\n",
    "            old_theta = self.theta.copy()\n",
    "            \n",
    "            # TODO:\n",
    "            # calculate predictions\n",
    "            # pred.shape: [n_samples, 1]\n",
    "\n",
    "            \n",
    "            # calculate gradients\n",
    "            # grad.shape:  [n_features, 1]\n",
    "\n",
    "            \n",
    "            # update the coefficients\n",
    "            \n",
    "            # END\n",
    "            \n",
    "            n_epoch += 1\n",
    "            tol = np.sum(np.abs(self.theta - old_theta))\n",
    "\n",
    "    def predict(self, X, threshold):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : shape (n_samples, n_features)\n",
    "        threshold : threshold for make decision\n",
    "        Returns\n",
    "        -------\n",
    "        y : shape (n_samples,)\n",
    "            Predicted class label per sample, 1 or 0\n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        \n",
    "        # add the intercept to X\n",
    "        \n",
    "        # get the prediction y\n",
    "        \n",
    "        # return prediction y\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ultimate-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data, transform the target variable y to 0/1 values\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "attended-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model using the data, and print out the model coefficients w\n",
    "# we include the intercept term, so w is a vector with 3 components\n",
    "# print out the model coeffcients\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-duplicate",
   "metadata": {},
   "source": [
    "## 1.2 Plot the training data and the decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "superb-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training data (x axis: first feature, y axis: second feature), use different labels for the two classes\n",
    "\n",
    "# on the same figure, plot the boundary, a straight line showing the boundary separating p>0.5 from p<=0.5\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-liquid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
